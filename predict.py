import nltk.tokenize
import torch

def load_model(filename):
    model = None
    return model

def predict(model, x):
    Y = None
    with torch.no_grad():
        pass
        # predict

    return Y

def main():

    # parse args (file/stdin, )

    # load model

    # read input text

    # sent_tokenize if necessary

    # convert sentence to tensor

    # predict

    # convert output tensor to text

    return

if __name__ == "__main__":
    main()